---
title: "Regressão ordinal bayesiana - uma introdução"
author: "Igor Costa"
date: "10/05/2022"
output: pdf_document
---
# Motivação
Esse material pretende fazer uma breve introdução aos chamados modelos de regressão ordinais, ajustados a variáveis dependentes categórias ordinais, ou seja, em que a ordem dos elementos é importante (nível de escolaridade, respostas em escala do tipo Likert, etc). As discussões aqui feitas restringem-se ao campo da psicolinguística experimental.

## Recomendações de leitura:

- Gelman & Hill (2009). \emph{Data Analysis Using Regression and Multilevel/Hierarchical Models.} Mais especificamente: Cap. 5 Logistic regression (p. 79-105); Cap. 6.5 Multinomial regression (119-123); Cap. 15.2 Ordered categorical regression: storable votes (331-332).

- \href{https://vasishth.github.io/bayescogsci/book/}{\color{teal}{Nicenboim, B., Schad, D. \& Vasishth, S. \emph{An Introduction to Bayesian Data Analysis for Cognitive Science.}}}

- \href{https://bookdown.org/content/3686/ordinal-predicted-variable.html}{\color{teal}{Kurz, S. \emph{Doing Bayesian Data Analysis in brms and the tidyverse.}}} Mais especificamente: Cap. 23 - \emph{Ordinal Predicted Variable.}

## Carregando os pacotes adequados
```{r, message=FALSE}
require(ggplot2)
require(dplyr)
require(RColorBrewer)
require(tidyr)
require(scales)
require(brms) # Esse o pacote para fazermos o modelo ordinal bayesiano
require(sjPlot) # Fundamental para extrair os efeitos marginais (última etapa deste tutorial)
require(tidybayes)
```

# Carregamento e organização dos dados brutos
Carregando os dados de um experimento com Escala Likert:
```{r}
dados <-
  read.csv("https://raw.githubusercontent.com/igordeo-costa/ModelosOrdinais/main/ScalaLikertCosta2022.csv",
           stringsAsFactors = T)
```

Transformando demais as variáveis de modo adequado
```{r}
dados$idade<-as.integer(dados$idade)
dados$subj <- as.factor(dados$subj)
```

Mudar os dados respostas para ordenados
```{r}
dados$answer<-as.ordered(dados$answer)
```

# Investigando os dados - Análise descritiva

Contagem dos valores brutos:
```{r}
contag <- dados %>%
  group_by(Ordem, Num, answer) %>%
  tally() %>%
  group_by(Ordem, Num) %>%
  spread(answer, n)

colnames(contag) <- c("Ordem", "Num",
                      "Discordo_Totalmente", "Discordo", "Neutro",
                      "Concordo", "Concordo_Totalmente")

contag
```

Cálculo das porcentagens respectivas (tabela em formato horizontal)

```{r}
porc_horiz <- dados %>%
  group_by(Ordem, Num, answer) %>%
  tally() %>%
  mutate(perc=n/sum(n)) %>%
  dplyr::select(-n) %>%
  group_by(Ordem, Num) %>%
  spread(answer, perc)

colnames(porc_horiz) <- c("Ordem", "Num",
                          "Discordo_Totalmente", "Discordo", "Neutro",
                          "Concordo", "Concordo_Totalmente")

porc_horiz
```

## Gráfico de barras empilhadas para fácil visualização
Essa parte é difícil de compreender se não temos a noção do resultado final. Você pode rodá-la e voltar depois com calma para entender os códigos. Resumidamente: vamos fazer um gráfico de barras empilhadas centrado na categoria "neutro", ou seja, no meio da escala. Para isso, vamos criar dois conjuntos de dados: as porcentagens da parte de cima ("concordo" e "concordo totalmente') e as da parte de baixo ("discordo" e "discordo totalmente"). A categoria "neutro" será dividida em duas e cada pedaço anexado a uma das partes acima. 

Dividir o meio da escala (os julgamentos "Neutro"):
```{r}
dados_meio <- porc_horiz %>%
  mutate(c1 = Neutro / 2,
         c2 = Neutro / 2) %>%
  select(Ordem, Num,
         Discordo_Totalmente, Discordo, c1, c2, Concordo, Concordo_Totalmente) %>%
  gather(key = answer, value = perc, 3:8)
```

Separar a escala em dois conjuntos, o "alto" e o "baixo":
```{r}
meio_alto <- dados_meio %>%
  filter(answer %in% c("Concordo_Totalmente", "Concordo", "c2")) %>%
  # Níveis na ordem normal!
  mutate(answer = factor(answer, levels = c("Concordo_Totalmente", "Concordo", "c2")))

meio_baixo <- dados_meio %>%
  filter(answer %in% c("c1", "Discordo", "Discordo_Totalmente")) %>%
  # Níveis na ordem inversa!
  mutate(answer = factor(answer, levels = c("Discordo_Totalmente", "Discordo", "c1")))
```

Estabelecer uma paleta de cores para organização!
```{r}
# Usar, do pacote RColorBrewer, a paleta de cores "spectral", com 5 cores 
legend_pal <- brewer.pal(name = "Spectral", n = 5)
# Duplica a cor do meio manualmente
legend_pal<-c("#2B83BA", "#ABDDA4", "#FFFFBF", "#FFFFBF", "#FDAE61", "#D7191C")
# Substitui a cor do meio por um cinza
legend_pal <- gsub("#FFFFBF", "#9C9C9C", legend_pal)
# Atribui nomes às cores
names(legend_pal) <-
  c("Concordo_Totalmente", "Concordo", "c1", "c2", "Discordo", "Discordo_Totalmente")
```

Produzir o gráfico, finalmente!
```{r}
ggplot() + 
  geom_bar(data = meio_alto, aes(x = Num, y=perc, fill = answer), stat="identity") +
  geom_bar(data = meio_baixo, aes(x = Num, y=-perc, fill = answer), stat="identity") +
  #-----------------------------------------------------------------------------
  # Essa parte do código é um pouco complicada...
  # Serve apenas para colocar os valores dentro das barras de modo alinhado...
  geom_text(data = meio_alto,
            aes(alpha = answer, x = Num, y=perc, group = answer,
                label = scales::percent(perc, accuracy = 1)),
            color = "white", size = 3.5, fontface = "bold",
            position = position_stack(vjust = .5)) +
  geom_text(data = meio_baixo,
            aes(alpha = answer, x = Num, y=-perc, group = answer,
                label = scales::percent(perc, accuracy = 1)),
            size = 3.5, color = "white", fontface = "bold",
            position = position_stack(vjust = .5),) +
  scale_alpha_manual(values = c("c1" = 0, "c2" = 0,
                                "Discordo" = 1, "Discordo_Totalmente" = 1,
                                "Concordo_Totalmente" = 1, "Concordo" = 1),
                     guide = 'none') +
  #-----------------------------------------------------------------------------
  geom_hline(yintercept = 0, color =c("black"), linetype = "dotted") +
  facet_wrap(~Ordem) +
  scale_y_continuous(breaks = seq(from = -1, to = 1, by = .2),
                     # Definir os valores negativos da legenda como positivos
                     labels = function(x) percent(abs(x))) +
  scale_fill_manual(values = legend_pal, 
                    breaks = c("Concordo_Totalmente", "Concordo", "c2",
                               "Discordo", "Discordo_Totalmente"),
                    labels = c("Concordo_Totalmente", "Concordo", "Neutro",
                               "Discordo", "Discordo_Totalmente")) +
  labs(x = "\nNúmero da Anáfora", y = "", fill = "") + 
  ggtitle("") + 
  theme_bw() +
  theme(axis.ticks.x = element_blank(), 
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        plot.background = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank())
```

# Ajustando um modelo ordinal misto

Agora vamos de fato ajustar um modelo ordinal bayesiano...

Verificando quais os contrastes dos dados:

```{r}
contrasts(dados$Num)
contrasts(dados$Ordem)
```

Mudar o nível-base para "um-todo" para facilitar a comparação entre as condições "um-todo" SG x PL

```{r}
dados$Ordem<-relevel(dados$Ordem, ref = "um-todo")
```

Ajustando um modelo de regressão ordinal bayesiano sem definição das priors informativas ("flat priors"). Este não é o melhor cenário, mas o objetivo aqui é apenas entender o funcionamento e implementação do modelo.

Vamos rodar o modelo mais completo, pois demora um pouco... ou muito, dependendo da capacidade de processamento do seu computador...

```{r, message=FALSE, warning=FALSE}
# Vamos garantir que o programa use toda a nossa capacidade de computação para acelerar o
# processo usando todos os núcleos do nosso processador
options(mc.cores = parallel::detectCores())

# Aqui de fato o modelo
m2 <- brm(answer ~ Ordem*Num + (1+Ordem*Num|subj)+(1+Ordem*Num|item),
          data = dados,
          family = cumulative(link = "logit", threshold = "flexible"),
          silent = 2, refresh = 0) # Apenas para não dar avisos no arquivo .pdf 

# Investigando apenas os fatores fixos
fixef(m2)[5:7,]
```

Você pode checar o ajuste do modelo, ou seja, a relação entre as priors e os dados. Neste caso, porém, ele será bom, visto que, com 'flat priors' o modelo usava os próprios dados como critério...
```{r, fig.width=5, fig.height=3}
pp_check(m2, ndraws = 100)

# Investigue também no formato de barras, se desejar
# pp_check(m2, type = "bars", ndraws = 100)

# Você pode investigar, inclusive, por groupo: 
pp_check(m2, type = "bars_grouped", ndraws = 100, group = "Ordem")
```

## Visualizando as estimativas

Extraindo os coefientes dos fatores fixos e intervalos de confiança calculados
```{r}
fixos.m<-fixef(m2)[5:7,]

# Prepara um data frame com esses dados
colnames(fixos.m)<-c("Estimativas", "Est.Error", "lower", "upper")
fixos.m<-as.data.frame(fixos.m)

# Calcula da chance e das probabilidades correspondentes
fixos.m<-fixos.m %>%
  mutate(Odds=exp(Estimativas)) %>%
  mutate(Probs=if_else(Estimativas<0, # Se logOdds menor do que zero, então:
                       (exp(Estimativas)/(1 + exp(Estimativas))-1)*100, # Probab. de descer na escala
                       exp(Estimativas)/(1 + exp(Estimativas))*100)) # Probab. de subir na escala

rownames(fixos.m)<-c("ORDEM: todo_um", "NÚMERO: singular", "INTERAÇÃO: ordem x número")

round(fixos.m, 3)
``` 

Agora vamos plotar o gráfico para publicação...
```{r, fig.width=5, fig.height=3}
fixos.m %>%
  ggplot(aes(x=reorder(rownames(fixos.m), Estimativas),
             y=Estimativas))+
  geom_hline(yintercept = 0, linetype = "dashed", color = "grey")+
  geom_errorbar(aes(ymin=lower, ymax=upper), width=.0,
                position=position_dodge(.9))+
  geom_point(color="orange", size = 3)+
  geom_text(aes(label=round(Estimativas, 3)), vjust=-1)+
  # Ao mudar a ordem é preciso mudar aqui embaixo...
  scale_x_discrete(labels=c("ORDEM: todo_um", "NÚMERO: Singular",
                            "INTERAÇÃO:\n\ntodo_um x singular")) +
  labs(y = "LogOdds", x = "") + 
  ggtitle("Intervalos de credibilidade (0.95)") +
  coord_flip()+theme_classic()
``` 

Uma outra forma de pensar sobre esse gráfico é olhar para a relação entre a distribuição das estimativas dos fatores fixos e os interceptos (tau-cuts $\tau$) estimados pelo modelo. A informação dada, no final, é a mesma do gráfico anterior, mas talvez fique mais claro o que aquele gráfico está mostrando.

Primeiro, vamos extrair os desvios padrão e estimativas da posterior:
```{r}
(posterior.draws <- m2 %>%
  spread_draws(`b_.*`, regex = TRUE) %>%
  summarise_draws())
```

Em seguida, vamos plotar um gráfico com alguns desses dados: 

```{r, fig.width=7, fig.height=3}
legend_pal <- c("#ABDDA4", "#FDAE61", "#D7191C")
  
data.frame(
  fatores = c("Todo_um", "Singular", "Interação"),
  posterior.draws[5:7,2:4]) %>%
  expand(nesting(fatores, mean, sd),
         y = seq(from = -4, to = 4, by = 0.001)) %>%
  mutate(d = dnorm(y, mean, sd)) %>%
  ggplot(aes(x = y, y = d, fill = fatores)) +
  geom_density(stat = "identity", alpha = 0.5,
               aes(color = fatores)) +
  geom_vline(xintercept = fixef(m2)[1:4, 1], linetype = "dotted") +
  scale_x_continuous(
    sec.axis = dup_axis(breaks = fixef(m2)[1:4, 1] %>%
                          as.double(),
                        labels = parse(text = stringr::str_c("tau[", 1:4, "]")))) +
  scale_fill_manual(values = legend_pal, name = NULL) +
  scale_color_manual(values = legend_pal, name = NULL) +
  labs(y = "", x = "", fill = "") +
  theme_bw() +
  theme(axis.ticks.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.y = element_blank(),
        plot.background = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank())
```


## Interpretando os resultados...

A fim de entender os resultados, primeiro devemos lembrar os contrastes do modelo. Neste caso, estamos usando 'dummy code' (0 e 1), também chamado de 'treatment contrasts'. Não vamos entrar em detalhes aqui sobre outros tipos de contrastes. Para uma discussão introdutória, veja o excelente material disponível \href{https://vasishth.github.io/Freq_CogSci/ch-contr.html}{\color{teal}{aqui}}.

```{r}
contrasts(dados$Num)
contrasts(dados$Ordem)
```

As categorias codificadas com 0 (zero) formam a base, a referência contra as quais as demais serão contrastadas. Neste caso, um_todo (0) PL (0) é a categoria de referência. Logo, podemos entender assim as estimativas do modelo:

- O preditor 'Ordem: todo_um' = -2.4 logOdds indica o contraste 'todo_um (1) PL (0)' $\times$ 'um_todo (0) PL (0)'. Ou seja, mantendo-se o número constante, o efeito da 'ordem': todo_um aumenta a probabilidade de se DESCER na escala, aumenta a probabilidade de se dar uma resposta mais abaixo na escala.

- O preditor 'Número: singular' = +1.6 logOdds indica o contraste 'um_todo (0) SG (1)' x 'um_todo (0) PL (0)'. Ou seja, mantendo-se a ordem constante, o efeito do 'número': singular aumenta a probabilidade de se SUBIR na escala, aumenta a probabilidade de se dar uma resposta mais acima na escala.

- A interação 'Ordem x Número (todo_um singular)' = +1.6 logOdds indica que os níveis da variável 'Ordem' interagem com os níveis da variável 'Número', basicamente indicando que: o nível singular aumenta a probabilidade de SUBIR na escala com todo_um; o nível plural aumenta a probabilidade de DESCER na escala com todo_um.

\textbf{IMPORTANTE!}
O fato de haver um efeito de interação aponta para olharmos com cuidado para os efeitos de Ordem e de Número. Se não houvesse interação, o efeito de um nível da variável seria o mesmo para ambos os níveis da outra, mas como há, os efeitos de 'ordem' e de 'número' indicam contrastes particulares. Ver explicação abaixo, se quiser saber mais sobre esse ponto.

### Adendo 1: de logOdds para Odds para probailidades

Vamos começar com um vetor de probabilidades (valores entre 0 a 1, portanto), e vamos transformá-lo em logaritmo da chance (LogOdds). É esse valor que o modelo com ```family = 'logit'``` nos dá. Em seguida, vamos converter os LogOdds em Odds (chance) e depois em probabilidades.

```{r}
a = c(0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1)
log_a = round(qlogis(a), 2)
odds = round(exp(log_a), 1)
# Abaixo, o mesmo que 'boot::inv.logit(log_a)'
backTo_a = round(exp(log_a)/(1+exp(log_a)), 2)
tags = c("extreme", rep("border", 4), "center", rep("border", 4), "extreme")

(myOddsGraph <- data.frame(a, log_a, odds, backTo_a, tags))
```

A partir dessa tabela, temos o seguinte gráfico resumitivo:

```{r, echo=FALSE, , fig.width=6, fig.height=3}
myOddsGraph %>%
  ggplot() +
  geom_text(aes(x = 1, y = a, label = a, color = tags)) +
  geom_text(aes(x = 2, y = a, label = log_a, color = tags)) +
  geom_text(aes(x = 3, y = a, label = odds, color = tags)) +
  geom_segment(aes(x = 1.2, xend = 1.8, y = 0.52, yend = 0.52),
               arrow = arrow(length = unit(0.03, "npc")),
               color = "gray") +
  geom_text(aes(x = 1.5, y = 1/1.6, label = "qlogis(prob.)"),
            color = "gray", size = 3) +
  geom_segment(aes(x = 2.2, xend = 2.8, y = 1/2, yend = 1/2),
               arrow = arrow(length = unit(0.03, "npc")),
               color = "gray") +
  geom_text(aes(x = 2.5, y = 1/1.6, label = "exp(logOdds)"),
            color = "gray", size = 3) +
  geom_segment(aes(x = 1.8, xend = 1.2, y = 0.48, yend = 0.48),
               arrow = arrow(length = unit(0.03, "npc")),
               color = "gray") +
  geom_text(aes(x = 1.5, y = 0.26, label = "exp(logOdds)/(1+exp(logOdds))"),
            color = "gray", size = 3) +
  scale_x_continuous(labels = c("Probabilidades", "LogOdds", "Odds", "Probabilidades"),
                   breaks = seq(from = 1, to = 4, by = 1)) +
  scale_color_brewer(palette = "Set1", name = NULL) +
  labs(x = "", y = "") +
  theme_classic() +
  theme(legend.position = 'none',
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  coord_flip()
```


Olhando com atenção para esses dados, o que percebemos é que:

- Probabilidade de 50$\%$ é igual a 0 (zero) logOdds que é igual a chance de 1/1 (1 para 1, ou seja, uma chance de sucesso para uma de fracasso);

- Probabilidade de 80$\%$ é igual a 1.39 logOdds que é igual a chance de 4/1 (4 chances de sucesso para uma de fracasso);

- Probabilidade de 10$\%$ é igual a -2.2 logOdds que é igual a chance de 0.1 ou 1/10 (1 chance de sucesso para 10 de fracasso).

Mas por que usar logOdds se fica tão difícil de compreender? O motivo é que probabilidade é um valor limitado entre 0 e 1 enquanto LogOdds é um valor que vai de -Inf a +Inf:
```{r}
qlogis(0) # 0%
qlogis(1) # 100%
qlogis(.9999999999) # um valor muito próximo de 100% pode ser estimado em logOdds
qlogis(.0000000001) # um valor muito próximo de 0% pode ser estimado em logOdds
```

Assim sendo, uma outra maneira de ler as estimativas do modelo é interpretar as probabilidades (ou chances) correspondentes na tabela:

```{r}
round(fixos.m, 3)
```

Ao se mudar de uma frase com a ordem 'um_todo' para uma frase com a ordem 'todo_um', há cerca de 92$\%$ de probabilidade de a resposta ser 1 nível abaixo na escala (0.08 ou 1 chance para SUBIR e 12 para DESCER). Por exemplo, se as pessoas em geral marcam 'concordo' em uma frase com 'um_todo', há 92$\%$ de probabilidade de elas marcarem abaixo, ou seja, 'neutro', em uma frase com 'todo_um'.

Se as pessoas em geral marcam 'concordo' em uma frase com 'plural', há 83$\%$ de probailidade (ou 5 chances para SUBIR e 1 para DESCER) de elas marcarem acima, ou seja, 'concordo totalmente' em uma frase com anáfora 'singular'. \emph{Grosso modo}, é isso que o modelo está dizendo.

## Adendo 2: entendendo o efeito de interação

Observe o gráfico abaixo, cujos valores foram inventados, apenas para ilustração:

```{r, fig.width=5, fig.height=3}
data.frame(
  .ordem = c("um_todo", "um_todo", "todo_um", "todo_um"),
  .num = c("sg", "pl", "sg", "pl"),
  .porc = c(.8, .6, .7, .2),
  .sd = c(rep(.02, 4))) %>%
  ggplot(aes(x = .ordem, y = .porc, group = .num, color = .num)) +
  geom_errorbar(aes(ymin = .porc-.sd, ymax = .porc+.sd), width = .05) +
  geom_point(size = 2) + geom_line() +
  scale_y_continuous(labels = scales::label_percent(accuracy = 1L),
                     breaks = seq(from = 0, to = 1, by = .1))
```

Observe que mudar de plural (0) para singular (1) (ou vice-versa):

- Quando a ordem é 'um_todo', a mudança é de 20$\%$ (80 - 60) ou (60-80 = -20)
- Quando a ordem é 'todo_um', a mudança é de 50$\%$ (70 - 20) ou (20-70 = -50)
- A diferença é, portanto: 50 - 20 = 30 ou -50 - (-20) = -30

Observe também que mudar de 'um_todo' (0) para 'todo_um' (1) (ou vice-versa):

- Quando o número é 'singular', a mudança é de 10$\%$ (80 - 70) ou (70 - 80 = -10)
- Quando o número é plural, a mudança é de 40$\%$ (60 - 20) ou (20 - 60 = -40)
- A diferença é, portanto: 40 - 10 = 30 ou -40 - (-10) = -30

Repare que o "efeito de interação" é sempre o mesmo: a diferença das diferenças = 30$\%$ (ou -30$\%$ se for no sentido contrário, de 1 para 0). Por isso, não importa o modelo que você ajuste para esses dados, com quaisquer contrastes o valor da interação será o mesmo, mudando apenas o sinal em alguns casos!

Vamos fazer uma pequena mudança no gráfico, trocando aquele .2 por .5:
```{r, fig.width=5, fig.height=3}
data.frame(
  .ordem = c("um_todo", "um_todo", "todo_um", "todo_um"),
  .num = c("sg", "pl", "sg", "pl"),
  .porc = c(.8, .6, .7, .5),
  .sd = c(rep(.02, 4))) %>%
  ggplot(aes(x = .ordem, y = .porc, group = .num, color = .num)) +
  geom_errorbar(aes(ymin = .porc-.sd, ymax = .porc+.sd), width = .05) +
  geom_point(size = 2) + geom_line() +
  scale_y_continuous(labels = scales::label_percent(accuracy = 1L),
                     breaks = seq(from = 0, to = 1, by = .1))
```

Ao fazer isso, o que vemos é que o resultado, ao se mudar de 'plural' para 'singular' não é afetado pela 'ordem', que é 20$\%$ em ambos os casos: 20 - 20 = 0% de alteração de um nível para outro; O resultado ao se mudar de 'um_todo' para 'todo_um' não é afetado pelo 'número', que é 10% em ambos os casos: 10 - 10 = 0% de alteração de um nível para outro. Logo: não há efeito de interação!

Esse gráfico mostra bem, ainda, o que um modelo de regressão faz ao expor as 'estimativas'. Se não há interação, o efeito de 'singular' (aumento de 20$\%$) é o mesmo tanto em 'todo_um' quanto em 'um_todo'. Esse pensamento é difícil para quem vem de um paradigma mental típico da Análise de Variância (Anova), que pensa sempre em contrastes de todas as categorias contra todas as categorias, como se faz em um teste \emph{post-hoc}. O modelo de regressão contrasta apenas o que for estritamente necessário, não contrastando o que for redundante. Se, por exemplo, temos 3 categorias (A, B e C), ele apenas fará dois contrastes, porque o terceiro é inferível desses dois. Um exemplo pode deixar isso mais claro: se sabemos que Pedro é 5 anos mais velho do que João e que Maria é 2 anos mais velha do que Pedro, então não precisamos calcular a diferença de idade entre João e Maria, pois podemos inferi-la dos contrastes já dados. 

No caso de 4 condições nos dados com que estamos trabalhando, ao fixar uma delas no intercepto, o modelo precisa apenas contrastar duas delas e estimar a interação para ter tudo o que é necessário. Se não há interação, o efeito do número obtido do contraste de duas condições é o mesmo para o contraste entre as demais (e o modelo não precisa perder tempo calculando esse valor). Se há interação, então o efeito efeito do número obtido do contraste de duas condições não é o mesmo para as demais e o modelo está mostrando nas estimativas o contraste individual entre elas.

### Interpretando os resultados à luz da teoria

| Frase: O(a) estilista mostrou...         |Anáfora                  | Ordem     | Número    |
|------------------------------------------|-------------------------|-----------|-----------|  
| uma camisa para todo comprador que [...],| mas \textbf{ela} não... | Um_todo   | Singular  |
| uma camisa para todo comprador que [...],| mas \textbf{elas} não...| Um_todo   | Plural    |
| toda camisa que [...] para um comprador, | mas \textbf{ele} não... | Todo_um   | Singular  |
| toda camisa que [...] para um comprador, | mas \textbf{eles} não...| Todo_um   | Plural    |

- Sentenças duplamente quantificadas com anáfora singular são aceitas pelos falantes de Português Brasileiro se comparadas com sentenças com anáfora plural (maior porcentagem de julgamentos concordo totalmente e concordo) - Efeito de NÚMERO Singular do modelo: 83$\%$;

- No que diz respeito à ordem dos quantificadores, os resultados indicam que sentenças com a ordem todo_um não são aceitas pelos falantes de português - Efeito de ORDEM: Todo_um: -92$\%$. Este efeito, contudo, foi modulado pela interação, mostrando que se mantém para a condição Todo_um $\times$ Plural, mas não para Todo_um $\times$ Singular - Efeito de INTERAÇÃO: Todo_um $\times$ Singular: 84$\%$.

# Investigando os dados do Mario

Carregando os dados e fazendo as alterações na tabela:
```{r}
final_table <- read.csv(
  "https://raw.githubusercontent.com/igordeo-costa/ModelosOrdinais/main/AnaliseEscalaLikert_Mario.csv",
  stringsAsFactors = T)

# Preparando a tabela
final_table$escala <- as.ordered(final_table$escala) # variável resposta ordenada
```

## Preparando a estatística descritiva

Calculando valores absolutos
```{r}
resp_escala_abso <- final_table %>%
  filter(!is.na(escala)) %>% # Excluir células vazias NA
  group_by(Tamanho, Número, escala) %>% # agrupa pelas condições relevantes
  tally() %>% # Faz a contagem
  spread(escala, n)

colnames(resp_escala_abso) <- c("Tamanho", "Número",
                                "Nada_natural", "Pouco_natural", "Neutro",
                                "Muito_natural", "Totalmente_natural")
```


Calculando valores percentuais 
```{r}
resp_escala_perc <- final_table %>%
  filter(!is.na(escala)) %>%
  group_by(Tamanho, Número, escala) %>%
  tally() %>%
  mutate(perc=n/sum(n)) %>%
  select(-n) %>%
  spread(escala, perc)

colnames(resp_escala_perc) <- c("Tamanho", "Número",
                                "Nada_natural", "Pouco_natural", "Neutro",
                                "Muito_natural", "Totalmente_natural")
```

E aqui vamos fazer o gráfico de barras empilhadas:
```{r}
# Dividir o meio da escala (os julgamentos "Neutro"):
dados_meio <- resp_escala_perc %>%
  mutate(c1 = Neutro / 2,
         c2 = Neutro / 2) %>%
  select(Tamanho, Número,
         Nada_natural, Pouco_natural, c1, c2, Muito_natural, Totalmente_natural) %>%
  gather(key = Escolha, value = perc, 3:8)

# Separando a escala em dois conjuntos, o "alto" e o "baixo":
meio_alto <- dados_meio %>%
  filter(Escolha %in% c("Totalmente_natural", "Muito_natural", "c2")) %>%
  # Níveis na ordem normal!
  mutate(Escolha = factor(Escolha,
                          levels = c("Totalmente_natural", "Muito_natural", "c2")))

meio_baixo <- dados_meio %>%
  filter(Escolha %in% c("c1", "Pouco_natural", "Nada_natural")) %>%
  # Níveis na ordem inversa!
  mutate(Escolha = factor(Escolha,
                          levels = c("Nada_natural", "Pouco_natural", "c1")))

# Estabelecimento de uma paleta de cores para organização!
legend_pal<-c("#2B83BA", "#ABDDA4", "#FFFFBF", "#FFFFBF", "#FDAE61", "#D7191C")
legend_pal <- gsub("#FFFFBF", "#9C9C9C", legend_pal) 
names(legend_pal) <- c("Totalmente_natural", "Muito_natural", "c1",
                       "c2", "Pouco_natural", "Nada_natural")
```

Produzindo o gráfico, finalmente!
```{r}
ggplot() + 
  geom_bar(data = meio_alto, aes(x = Tamanho,
                                 y=perc, fill = Escolha), stat="identity") +
  geom_bar(data = meio_baixo, aes(x = Tamanho,
                                  y=-perc, fill = Escolha), stat="identity") +
#-----------------------------------------------------------------------------
# Essa parte do código é um pouco complicada...
# Serve apenas para colocar os valores dentro das barras
geom_text(data = meio_alto,
          aes(x = Tamanho, y=perc, group = Escolha,
              alpha = Escolha,
              label = scales::percent(perc, accuracy = 1)),
          color = "white",
          size = 3.5, position = position_stack(vjust = .5),
          fontface = "bold") +
  geom_text(data = meio_baixo,
            aes(x = Tamanho, y=-perc, group = Escolha,
                alpha = Escolha,
                label = scales::percent(perc, accuracy = 1)),
            size = 3.5, position = position_stack(vjust = .5),
            color = "white",
            fontface = "bold") +
  # Não mostrar as % no meio da escala!
  scale_alpha_manual(values = c("c1" = 0, "c2" = 0,
                                "Muito_natural" = 1, "Totalmente_natural" = 1,
                                "Nada_natural" = 1, "Pouco_natural" = 1),
                     guide = 'none') +
  #-----------------------------------------------------------------------------
  geom_hline(yintercept = 0, color = c("black"), linetype = "dotted") +
  scale_fill_manual(values = legend_pal, 
                    breaks = c("Totalmente_natural", "Muito_natural", "c2",
                               "Pouco_natural", "Nada_natural"),
                    labels = c("Totalmente_natural", "Muito_natural",
                               "Neutro", "Pouco_natural", "Nada_natural")) +
  labs(x = "", y = "", fill="") +
  facet_wrap(~Número) +
  theme_bw() +
  scale_y_continuous(labels = function(x) percent(abs(x)),
                     limits = c(-0.9, 1),
                     breaks = seq(from = -0.9, to = 1, by = .3)) +
  theme(axis.ticks.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.y = element_blank(),
        plot.background = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank()) +
  ggtitle("")
```

## Aplicando um modelo ordinal aos dados usando 'Flat priors'

```{r, message=FALSE, warning=FALSE}
# Ativando acesso a todos os núcleos do processador
options(mc.cores = parallel::detectCores())

# Ajustando o modelo
ordinal_mario <- brm(escala ~ Tamanho*Número +
                       (1+Tamanho*Número|Part) + (1+Tamanho*Número|num),
                     data = final_table,
                     family = cumulative(link = "logit", threshold = "flexible"),
                     silent = 2, refresh = 0)

fixef(ordinal_mario)[5:7,]
```

Checando a qualidade do ajuste...
```{r, fig.width=5, fig.height=3}
pp_check(ordinal_mario, ndraws = 100)
```

Extrair os coefientes dos fatores fixos e intervalos de confiança calculados
```{r}
fixos.m<-fixef(ordinal_mario)[5:7,]

# Preparar um data frame com esses dados
colnames(fixos.m)<-c("Estimativas", "Est.Error", "lower", "upper")
fixos.m<-as.data.frame(fixos.m)

# Cálculo da chance e das probabilidades
fixos.m<-fixos.m %>%
  mutate(Odds=exp(Estimativas)) %>%
  mutate(Probs=if_else(Estimativas<0, # Se logOdds menor do que zero, então:
                       (exp(Estimativas)/(1 + exp(Estimativas))-1)*100, # Probab. de descer na escala
                       exp(Estimativas)/(1 + exp(Estimativas))*100)) # Probab. de subir na escala

rownames(fixos.m)<-c("TAMANHO: longa", "NÚMERO: singular", "INTERAÇÃO: longa x sg")

round(fixos.m, 3)
```

Plotar um gráfico para publicação...

```{r, fig.width=5, fig.height=3}
fixos.m %>%
  ggplot(aes(x=reorder(rownames(fixos.m), Estimativas),
             y=Estimativas))+
  geom_hline(yintercept = 0, linetype = "dashed", color = "grey")+
  geom_errorbar(aes(ymin=lower, ymax=upper), width=.1,
                position=position_dodge(.9))+
  geom_point(color="orange", size = 3) +
  geom_text(aes(label=round(Estimativas, 3)), vjust=-1)+
  # ao mudar a ordem é preciso mudar aqui
  scale_x_discrete(labels=c("INTERAÇÃO:\n\nlonga x singular",
                            "TAMANHO: longa",
                            "NÚMERO: singular"))+
  labs(y = "LogOdds", x = "") + 
  ggtitle("Intervalos de credibilidade (0.95)") +
  coord_flip()+theme_classic()
```

E também o gráfico com a distribuição estimada da posterior para cada fator...

```{r}
(posterior.draws <- ordinal_mario %>%
  spread_draws(`b_.*`, regex = TRUE) %>%
  summarise_draws())
```

```{r, fig.width=7, fig.height=3}
legend_pal <- c("#ABDDA4", "#FDAE61", "#D7191C")
  
data.frame(
  fatores = c("Longa", "Singular", "Interação"),
  posterior.draws[5:7,2:4]) %>%
  expand(nesting(fatores, mean, sd),
         y = seq(from = -20, to = 20, by = 0.001)) %>%
  mutate(d = dnorm(y, mean, sd)) %>% # PDF da distribuição normal
  ggplot(aes(x = y, y = d, fill = fatores)) +
  geom_density(stat = "identity", alpha = 0.5,
               aes(color = fatores)) +
  geom_vline(xintercept = fixef(ordinal_mario)[1:4, 1], linetype = "dotted") +
  scale_x_continuous(
    sec.axis = dup_axis(breaks = fixef(ordinal_mario)[1:4, 1] %>%
                          as.double(),
                        labels = parse(text = stringr::str_c("tau[", 1:4, "]")))) +
  scale_fill_manual(values = legend_pal, name = NULL) +
  scale_color_manual(values = legend_pal, name = NULL) +
  labs(y = "", x = "", fill = "") +
  theme_bw() +
  theme(axis.ticks.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.y = element_blank(),
        plot.background = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank())
```

## Interpretando os resultados...

Lembrando nossos contrastes...
```{r}
contrasts(final_table$Tamanho)
contrasts(final_table$Número)
```

- O fator significativo número singular (+6 logOdds) indica o contraste Curta (0) sg (1) x Curta (0) pl (0): singular aumenta a chance de se SUBIR na escala...

- O efeito não significativo de tamanho indica que nada se pode inferir quanto ao tamanho. O intervalo de credibilidade cortando a linha do zero indica que o parâmetro populacional pode tanto ser menor quanto maior do que zero... ou mesmo zero. Mantendo-se o plural constante, ao se mudar de longa para curta, não se pode inferir que há diferença.

- O intervalo de credibilidade para a interação ora corta a linha do zero ora não. Apenas por motivos pedagógicos, vamos assumir que ele seja significativo. Se é assim, então o nível singular aumenta MUITO a probabilidade de SUBIR na escala com curta e aumenta POUCO ou NADA com longa. Mas por que o valor em logOdds é negativo (-3 logOdds)? Como falamos antes, o resultado da interação é sempre o mesmo, o que muda é apenas o sinal.

\textbf{IMPORTANTE!} Em uma abordagem bayesiana, em geral estamos mais preocupados com a estimativa do modelo e com o grau de confiança que temos nela e menos preocupados de essa estimativa ser ou não significativa, ou seja, menos preocupados com o fato de o intervalo de credibilidade conter ou não zero (Ver a \href{https://www.youtube.com/watch?v=UzoNYDrZnrk&list=PLz_LbfBra_0cvj0zYDGDCLK7CnZ1GGF3j&index=4&ab_channel=ShravanVasishth}{\color{teal}{aula 03 do Prof. Shravan Vasishth}}, mais especificamente a partir de 2h27min13seg).

### De novo um adendo para compreender a interação...
Vamos olhar para o gráfico abaixo:
```{r, fig.width=5, fig.height=3}
# Valores abaixo são inventados, apenas para ilustração
data.frame(.tamanho = c("curta", "curta", "longa", "longa"),
           .num = c("sg", "pl", "sg", "pl"),
           .porc = c(.8, .55, .65, .55),
           .sd = c(rep(.02, 4))) %>%
  ggplot(aes(x = .tamanho, y = .porc, group = .num, color = .num)) +
  geom_line() +
  geom_errorbar(aes(ymin = .porc-.sd, ymax = .porc+.sd), width = .05) +
  geom_point(size = 2) +
  scale_y_continuous(labels = scales::label_percent(accuracy = 1L),
                     breaks = seq(from = 0, to = 1, by = .05))
```

Quando se muda de plural (0) para singular (1):

- na curta: 55 - 80 = -25
- na longa: 55 - 65 = -10
- Diferença = -25 - (-10) = -15% (Sinal negativo)

Quando se muda de singular (1) para plural (0):

- na curta: 80 - 55 = 25
- na longa: 65 - 55 = 10
- Diferença = 25 -10 = 15% (Sinal positivo)

Quando se muda de curta (0) para longa (1):

- no singular 80 - 65 = 15
- no plural 60 - 60 = 0
- Diferença = 15% (Sinal positivo)

Quando se muda de longa (1) para curta (0):

- no singular 65 - 80 = -15
- no plural 60 - 60 = 0
- Diferença = -15% (Sinal negativo)

Se você quiser ver como fica sem o efeito de interação, basta mudar o segundo .55 para .7:
```{r, fig.width=5, fig.height=3}
# Valores abaixo são inventados, apenas para ilustração
data.frame(.tamanho = c("curta", "curta", "longa", "longa"),
           .num = c("sg", "pl", "sg", "pl"),
           .porc = c(.8, .7, .65, .55),
           .sd = c(rep(.02, 4))) %>%
  ggplot(aes(x = .tamanho, y = .porc, group = .num, color = .num)) +
  geom_line() +
  geom_errorbar(aes(ymin = .porc-.sd, ymax = .porc+.sd), width = .05) +
  geom_point(size = 2) +
  scale_y_continuous(labels = scales::label_percent(accuracy = 1L),
                     breaks = seq(from = 0, to = 1, by = .05))
```

### Interpretando os resultados à luz da teoria
A partir de agora, o autor pode interpretar os resultados em vista das suas considerações teóricas, olhando para os contrastes que planejou, suas sentenças e categorizações respectivas:

| Frase                                                                                 | Tamanho | Número    |
|---------------------------------------------------------------------------------------|---------|-----------|  
| No escritório da firma desapareceu um documento sigiloso.                             | Curta   | Singular  |
| No escritório da firma desapareceu uns documentos sigilosos.                          | Curta   | Plural    |
| No canteiro do jardim desabrochou \textbf{repentinamente} uma azaleia belíssima.      | Longa   | Singular  |
| No canteiro do jardim desabrochou \textbf{repentinamente} umas azaleias belíssimas.   | Longa   | Plural    |

- O singular aumenta a probabilidade de respostas ACIMA na escala, indicando que os falantes aceitam mais as sentenças com número singular do que com número plural - Efeito de NÚMERO: Singular: 99$\%$;

- Esse efeito, porém, foi modulado pela interação: enquanto o plural tem o mesmo efeito nos falantes, independentemente do TAMANHO (efeito não significativo de TAMANHO: Longa), o singular é mais aceito com curtas do que com longas: Efeito de INTERAÇÃO: Longa $\times$ Singular: -96$\%$.

# Ajustando um modelo com priors informativas (ou nem tanto)

\textbf{NOTA DO AUTOR:} Recomendo não discutirmos esses pontos agora. Acho que poderíamos nos aprofundar mais antes de avançarmos aqui. Comecei meus estudos pelas aulas disponíveis no Youtube do Prof. Shravan Vasishth. \href{https://www.youtube.com/watch?v=dhbdG3gXP14&list=PLz_LbfBra_0cvj0zYDGDCLK7CnZ1GGF3j&ab_channel=ShravanVasishth}{\color{teal}{A primeira aula}} me parece fundamental para entender o que é uma função de verossimilhança (\emph{Likelihood function}). Relembrem também as aulas do Gilberto, em que ele trabalhou esse ponto com bastante atenção, dando vários exemplos. Sem esse conhecimento fica muito difícil avançar para \href{https://www.youtube.com/watch?v=V96A5T6dN6Y&list=PLz_LbfBra_0cvj0zYDGDCLK7CnZ1GGF3j&index=2&ab_channel=ShravanVasishth}{\color{teal}{a segunda aula}}, em que ele discute a noção de priors, fundamentando os princípios matemáticos por trás dessa noção. Relembrem também a última aula do Gilberto, em que ele trabalhou a noção de priors, com um exemplo de uma moeda não viciada. Da \href{https://www.youtube.com/watch?v=UzoNYDrZnrk&list=PLz_LbfBra_0cvj0zYDGDCLK7CnZ1GGF3j&index=3&ab_channel=ShravanVasishth}{\color{teal}{terceira aula}}, eu tirei a citação abaixo (1h38min08seg) que justifica o fato de, por enquanto, podermos ficar com esse modelo mais simples, sem priors tão informativas:

> In general, we don't want our priors to have too much influence on our posterior. This is unless we have \emph{very} good reasons for having informative priors, such as very small sample and/or a lot of prior information; an exemple would be if we have data from an impaired population, which makes it hard to increase our sample size. 

Eu ainda estou estudano o assunto e podemos ter uma conversa informal sobre o tema no dia da apresentação.